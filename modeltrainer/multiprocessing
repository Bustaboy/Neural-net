from multiprocessing import Process
import pickle
from datetime import datetime, timedelta
import logging
import os

class ModelTrainer:
    def __init__(self, db_manager: EnhancedDatabaseManager, config: Dict[str, Any]):
        self.db_manager = db_manager
        self.config = config
        self.model = None
        self.scaler = StandardScaler()
        self.model_path = "models/random_forest_model.pkl"
        self.scaler_path = "models/scaler.pkl"
        self.temp_model_path = "models/temp_random_forest_model.pkl"
        self.temp_scaler_path = "models/temp_scaler.pkl"
        os.makedirs("models", exist_ok=True)
        self.logger = logging.getLogger(__name__)
        self.feature_columns = [
            'price', 'quantity', 'confidence', 'fees',
            'btc_price', 'btc_dominance', 'volatility_index', 'fear_greed_index'
        ]
        self.min_samples = 100
        self.last_train_time = None
        self.training_in_progress = False

    def prepare_data(self, lookback_days: int = 30) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        # Unchanged from previous implementation
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=lookback_days)
            with self.db_manager.pool.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT t.*, m.btc_price, m.btc_dominance, m.volatility_index, m.fear_greed_index
                    FROM trades t
                    LEFT JOIN market_conditions m ON t.timestamp = m.timestamp
                    WHERE t.timestamp >= ? AND t.timestamp <= ?
                """, (start_date.isoformat(), end_date.isoformat()))
                trades = [dict(row) for row in cursor.fetchall()]

            if len(trades) < self.min_samples:
                self.logger.warning(f"Insufficient data: {len(trades)} samples")
                return None, None, self.feature_columns

            df = pd.DataFrame(trades)
            available_features = [col for col in self.feature_columns if col in df.columns]
            df = df[available_features].fillna(df[available_features].mean())
            df['label'] = (df['profit_loss'] > 0).astype(int)

            X = df[available_features].values
            y = df['label'].values
            return X, y, available_features
        except Exception as e:
            self.logger.error(f"Error preparing data: {e}")
            return None, None, self.feature_columns

    def train_model(self, lookback_days: int = 30, reason: str = "Scheduled"):
        """Train model in a separate process."""
        try:
            if self.training_in_progress:
                self.logger.info("Training already in progress, skipping")
                return
            self.training_in_progress = True

            def train_process():
                try:
                    X, y, feature_columns = self.prepare_data(lookback_days)
                    if X is None:
                        return

                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=0.2, random_state=42, stratify=y
                    )
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)

                    model = RandomForestClassifier(
                        n_estimators=100,
                        max_depth=5,
                        min_samples_split=5,
                        random_state=42,
                        class_weight='balanced'
                    )
                    model.fit(X_train_scaled, y_train)

                    y_pred = model.predict(X_test_scaled)
                    accuracy = accuracy_score(y_test, y_pred)

                    with open(self.temp_model_path, 'wb') as f:
                        pickle.dump(model, f)
                    with open(self.temp_scaler_path, 'wb') as f:
                        pickle.dump(scaler, f)

                    self.db_manager.log_system_event(
                        event_type="MODEL_TRAINING",
                        message=f"Model retrained ({reason}) with {len(X)} samples, accuracy: {accuracy:.2f}",
                        severity="INFO",
                        component="ModelTrainer"
                    )
                except Exception as e:
                    self.db_manager.log_system_event(
                        event_type="MODEL_TRAINING_ERROR",
                        message=f"Training failed: {str(e)}",
                        severity="ERROR",
                        component="ModelTrainer"
                    )
                finally:
                    self.training_in_progress = False

            p = Process(target=train_process)
            p.start()
        except Exception as e:
            self.logger.error(f"Error starting training process: {e}")
            self.training_in_progress = False

    def swap_model(self):
        """Swap to the newly trained model atomically."""
        try:
            if os.path.exists(self.temp_model_path) and os.path.exists(self.temp_scaler_path):
                with open(self.temp_model_path, 'rb') as f:
                    new_model = pickle.load(f)
                with open(self.temp_scaler_path, 'rb') as f:
                    new_scaler = pickle.load(f)

                os.rename(self.temp_model_path, self.model_path)
                os.rename(self.temp_scaler_path, self.scaler_path)

                self.model = new_model
                self.scaler = new_scaler
                self.last_train_time = datetime.now()
                self.logger.info("Model swapped successfully")
        except Exception as e:
            self.logger.error(f"Error swapping model: {e}")

    def load_model(self) -> bool:
        # Unchanged from previous
        try:
            if os.path.exists(self.model_path) and os.path.exists(self.scaler_path):
                with open(self.model_path, 'rb') as f:
                    self.model = pickle.load(f)
                with open(self.scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                self.logger.info("Model and scaler loaded")
                return True
            return False
        except Exception as e:
            self.logger.error(f"Error loading model: {e}")
            return False

    def should_retrain(self) -> Tuple[bool, str]:
        # Unchanged from previous
        try:
            if self.last_train_time is None or (datetime.now() - self.last_train_time) > timedelta(days=1):
                return True, "Daily schedule"
            with self.db_manager.pool.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT volatility_index
                    FROM market_conditions
                    ORDER BY timestamp DESC
                    LIMIT 1
                """)
                row = cursor.fetchone()
                if row and row['volatility_index'] > 0.75:
                    return True, "High volatility detected"
            return False, "No retraining needed"
        except Exception as e:
            self.logger.error(f"Error checking retrain condition: {e}")
            return False, "Error"
